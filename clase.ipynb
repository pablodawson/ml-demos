{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolucion 1D (discreta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$s(t) = \\sum_{-\\infty}^{\\infty} x(a) \\omega (t-a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$ : input \\\n",
    "$w$ : kernel \\\n",
    "$p$ : padding \\\n",
    "$s$ : stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1D(x, w, p=0 , s=1): \n",
    "  '''\n",
    "\n",
    "  '''\n",
    "  assert len(w) <= len(x), \"x debe ser mayor a w\"\n",
    "  assert p >= 0, \"padding debe ser positivo\"\n",
    "\n",
    "  w_r = np.array(w[::-1]) #rotation of w \n",
    "  x_padded = np.array(x)\n",
    "\n",
    "  if p > 0 :\n",
    "    zeros = np.zeros(shape = p)\n",
    "    x_padded = np.concatenate([zeros, x_padded, zeros]) #ceros hasta completar el padding\n",
    "\n",
    "  out = []\n",
    "\n",
    "  for i in range(0, int((len(x_padded) - len(w_r))) + 1 , s):\n",
    "    out.append(np.sum(x_padded[i:i + w_r.shape[0]] * w_r))\n",
    "  return np.array(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test con datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [3,6,8,2,1,4,7,9]\n",
    "w = [2 ,3, 6, 3, 2]\n",
    "w= np.array(w)/np.max(w)\n",
    "\n",
    "s = conv1D(x,w,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Graficar x\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.stem(x, use_line_collection=True)\n",
    "plt.title(\"Secuencia x\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "\n",
    "# Graficar w\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.stem(w, use_line_collection=True)\n",
    "plt.title(\"Secuencia w (Kernel)\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "\n",
    "# Graficar el resultado de la convolución\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.stem(s, use_line_collection=True)\n",
    "plt.title(\"Resultado de la Convolución\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolucion 2D (Imagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S(i,j) = (I*K) (i,j) = \\sum_m \\sum_n I(i-m,j-n) K(m,n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(I, K):\n",
    "    \"\"\"\n",
    "    Realizar una convolución 2D entre las matrices A y B.\n",
    "    \"\"\"\n",
    "    # Dimensiones de las matrices\n",
    "    i_rows, i_cols = I.shape\n",
    "    k_rows, k_cols = K.shape\n",
    "\n",
    "    # Matriz resultante con tamaño adecuado\n",
    "    result = np.zeros((i_rows + k_rows - 1, i_cols + k_cols - 1))\n",
    "\n",
    "    # Realizar la convolución\n",
    "    for i in range(i_rows):\n",
    "        for j in range(i_cols):\n",
    "            result[i:i+k_rows, j:j+k_cols] += I[i, j] * K\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"ejemplo.jpg\").resize((100,100)).convert('L')\n",
    "print(np.array(img).shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.array(img)\n",
    "K = np.array([[-1, 0, 1], \n",
    "            [-1, 0, 1], \n",
    "            [-1, 0, 1]])\n",
    "print(K.shape)\n",
    "Image.fromarray((K*255/np.max(K)).astype(np.uint8)).resize((100,100), Image.NEAREST) # Visualizar kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar convolucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = conv2D(I, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_vis =  (255* S / S.max()).astype(np.uint8)\n",
    "Image.fromarray(S_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eficiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicar_matrices(A, B):\n",
    "    \"\"\"\n",
    "    Multiplicar dos matrices A y B usando bucles for.\n",
    "    \"\"\"\n",
    "    # Obtener dimensiones de las matrices\n",
    "    filas_A, columnas_A = A.shape\n",
    "    filas_B, columnas_B = B.shape\n",
    "    \n",
    "    # Verificar si las matrices son multiplicables\n",
    "    if columnas_A != filas_B:\n",
    "        raise ValueError(\"Las columnas de A deben ser iguales a las filas de B para multiplicar.\")\n",
    "    \n",
    "    # Crear una matriz resultante con ceros\n",
    "    resultado = np.zeros((filas_A, columnas_B))\n",
    "    \n",
    "    # Realizar la multiplicación\n",
    "    for i in range(filas_A):\n",
    "        for j in range(columnas_B):\n",
    "            suma = 0\n",
    "            for k in range(columnas_A): # También es igual a filas_B\n",
    "                suma += A[i, k] * B[k, j]\n",
    "            resultado[i, j] = suma\n",
    "            \n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "I1 = np.array(img)\n",
    "I2 = np.array(img)*0.5\n",
    "\n",
    "w, h = I1.shape\n",
    "\n",
    "out = multiplicar_matrices(I1, I2)\n",
    "\n",
    "print(\"Tiempo de ejecución multiplicacion de matriz: %s segundos\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "S = conv2D(I1, K)\n",
    "print(\"Tiempo de ejecución convolucion: %s segundos\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pools(img: np.array, pool_size: int, stride: int) -> np.array:\n",
    "    # To store individual pools\n",
    "    pools = []\n",
    "    \n",
    "    # Iterate over all row blocks (single block has `stride` rows)\n",
    "    for i in np.arange(img.shape[0], step=stride):\n",
    "        # Iterate over all column blocks (single block has `stride` columns)\n",
    "        for j in np.arange(img.shape[0], step=stride):\n",
    "            \n",
    "            # Extract the current pool\n",
    "            mat = img[i:i+pool_size, j:j+pool_size]\n",
    "            \n",
    "            # Make sure it's rectangular - has the shape identical to the pool size\n",
    "            if mat.shape == (pool_size, pool_size):\n",
    "                # Append to the list of pools\n",
    "                pools.append(mat)\n",
    "                \n",
    "    # Return all pools as a Numpy array\n",
    "    return np.array(pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(pools: np.array) -> np.array:\n",
    "    # Total number of pools\n",
    "    num_pools = pools.shape[0]\n",
    "    # Shape of the matrix after pooling - Square root of the number of pools\n",
    "    # Cast it to int, as Numpy will return it as float\n",
    "    # For example -> np.sqrt(16) = 4.0 -> int(4.0) = 4\n",
    "    tgt_shape = (int(np.sqrt(num_pools)), int(np.sqrt(num_pools)))\n",
    "    # To store the max values\n",
    "    pooled = []\n",
    "    \n",
    "    # Iterate over all pools\n",
    "    for pool in pools:\n",
    "        # Append the max value only\n",
    "        pooled.append(np.max(pool))\n",
    "        \n",
    "    # Reshape to target shape\n",
    "    return np.array(pooled).reshape(tgt_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_output = np.array([\n",
    "    [10, 12,  8,  7],\n",
    "    [ 4, 11,  5,  9],\n",
    "    [18, 13,  7,  7],\n",
    "    [ 3, 15,  2,  2]\n",
    "])\n",
    "max_pooling(conv_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize(size=(224, 224))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pools = get_pools(img=np.array(img), pool_size=2, stride=2)\n",
    "img_pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = max_pooling(pools=img_pools)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(output.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red convolucional\n",
    "Fuente:  \"Introduction to Deep Learning with PyTorch\" Chanseok Kang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(49 * 10, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply conv followed by relu, then in next line pool\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Apply conv followed by relu, then in next line pool\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Prepare the image for the fully connected layer\n",
    "        x = x.view(-1, 7 * 7 * 10)\n",
    "        \n",
    "        # Apply the fully connected layer and return the result\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transform the data to torch tensors and normalize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307), (0.3081))\n",
    "])\n",
    "\n",
    "# Preparing the training and test set\n",
    "trainset = torchvision.datasets.MNIST('mnist', train=True, transform=transform, download=True)\n",
    "testset = torchvision.datasets.MNIST('mnist', train=False, transform=transform, download=True)\n",
    "\n",
    "# Prepare loader\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir optimizador y criterio para loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pablo\\ml-demos\\clase.ipynb Cell 42\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Compute the forward pass\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Compute the loss function\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\Pablo\\miniconda3\\envs\\joint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Pablo\\ml-demos\\clase.ipynb Cell 42\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Apply conv followed by relu, then in next line pool\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pablo/ml-demos/clase.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# Apply conv followed by relu, then in next line pool\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pablo\\miniconda3\\envs\\joint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Pablo\\miniconda3\\envs\\joint\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Pablo\\miniconda3\\envs\\joint\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    inputs, labels = data\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute the forward pass\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # Compute the loss function\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Compute the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
